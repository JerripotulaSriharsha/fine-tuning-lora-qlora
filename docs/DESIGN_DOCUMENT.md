# Credit Risk Assessment System - Design Document

**Version:** 1.0.0
**Date:** November 2025
**Project:** Fine-Tuning LoRA/QLoRA for Credit Risk Classification
**Author:** AI/ML Engineering Team

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [System Architecture](#system-architecture)
3. [Data Architecture](#data-architecture)
4. [Model Architecture](#model-architecture)
5. [User Interface Design](#user-interface-design)
6. [API Design](#api-design)
7. [Training Pipeline Design](#training-pipeline-design)
8. [Deployment Architecture](#deployment-architecture)
9. [Security and Privacy](#security-and-privacy)
10. [Performance Considerations](#performance-considerations)

---

## 1. Executive Summary

### 1.1 Project Overview

The Credit Risk Assessment System is an AI-powered solution that leverages parameter-efficient fine-tuning techniques (LoRA and QLoRA) to classify customers into three credit risk categories: **Good**, **Bad**, and **Standard**. The system is built on top of the Qwen2.5-3B-Instruct language model and provides multiple deployment interfaces including a web UI, REST API, and direct inference scripts.

### 1.2 Design Goals

- **Accuracy**: Achieve >50% classification accuracy compared to 20% baseline
- **Efficiency**: Enable training on consumer-grade GPUs (8GB VRAM)
- **Accessibility**: Provide multiple interfaces (Web UI, API, CLI)
- **Scalability**: Support parallel model comparison and batch inference
- **Maintainability**: Modular architecture with clear separation of concerns

### 1.3 Key Innovations

- **GRPO Training**: Group Relative Policy Optimization with multi-objective reward functions
- **Parameter Efficiency**: 4-bit quantization enabling 3B model training on 8GB GPU
- **Multi-Model Comparison**: Side-by-side evaluation of Base, LoRA, and QLoRA variants
- **Production Ready**: Complete deployment stack with streaming inference

---

## 2. System Architecture

### 2.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER LAYER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web UI (Streamlit)  â”‚  REST API Client  â”‚  CLI Tools           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                    â”‚
           v                  v                    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APPLICATION LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  app.py             â”‚  api_server.py     â”‚  infer.py            â”‚
â”‚  (Streamlit)        â”‚  (FastAPI)         â”‚  (CLI)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                    â”‚
           v                  v                    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INFERENCE LAYER                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  load_qlora_model.py  â”‚  load_lora_model.py  â”‚ load_base_model.pyâ”‚
â”‚  (GGUF Loaders)       â”‚  (GGUF Loaders)      â”‚ (GGUF Loaders)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                    â”‚
           v                  v                    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MODEL LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  qwen2.5-3b-f16-qlora.gguf  â”‚  qwen2.5-3b--lora-f16.gguf       â”‚
â”‚  (6.18 GB)                  â”‚  (6.18 GB)                        â”‚
â”‚  qwen2.5-3b-instruct-q8_0.gguf  (3.61 GB)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TRAINING PIPELINE                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  train_qlora.ipynb  â”‚  train_sft_qlora.ipynb  â”‚  trainlora.ipynbâ”‚
â”‚  (GRPO Training)    â”‚  (SFT Training)         â”‚  (Full LoRA)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                  â”‚                    â”‚
           v                  v                    v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      DATA LAYER                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  creditmix_dataset.json (31,868 examples)                       â”‚
â”‚  evaluation_examples.json (10 test cases)                       â”‚
â”‚  test.csv (50,000 raw records)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Component Responsibilities

| Component | Responsibility | Technology |
|-----------|---------------|------------|
| **Web UI** | Interactive credit risk assessment | Streamlit |
| **API Server** | RESTful inference endpoints | FastAPI |
| **Model Loaders** | Model loading and inference orchestration | llama.cpp, Python |
| **Training Pipeline** | Model fine-tuning and evaluation | Unsloth, TRL, PEFT |
| **Data Processor** | Input formatting and validation | Python |

---

## 3. Data Architecture

### 3.1 Input Schema

**Customer Financial Profile**
```python
{
    "age": int,                          # 18-100 years
    "occupation": str,                   # Job title
    "annual_income": float,              # USD, positive
    "outstanding_debt": float,           # USD, positive
    "credit_utilization": float,         # 0-100%
    "payment_behavior": str              # Enum of 6 categories
}
```

**Payment Behavior Categories:**
1. `Low_spent_Small_value_payments`
2. `High_spent_Medium_value_payments`
3. `Low_spent_Medium_value_payments`
4. `Low_spent_Large_value_payments`
5. `High_spent_Large_value_payments`
6. `High_spent_Small_value_payments`

### 3.2 Output Schema

**Credit Risk Classification**
```xml
<reasoning>
[Model's analytical reasoning about the customer's financial profile]
</reasoning>
<answer>
[One of: "Good", "Bad", "Standard"]
</answer>
```

### 3.3 Training Dataset Structure

**File:** `creditmix_dataset.json`

```json
{
  "question": "Age: X, Occupation: Y, Annual Income: Z, Outstanding Debt: W, Credit Utilization Ratio: V, Payment Behaviour: U",
  "answer": "Good|Bad|Standard"
}
```

**Dataset Statistics:**
- Total examples: 31,868
- Balanced version: 22,764 (7,588 per class)
- Distribution:
  - Good: 30.4% (9,685 examples)
  - Standard: 45.8% (14,595 examples)
  - Bad: 23.8% (7,588 examples)

### 3.4 Data Flow

```
Raw CSV (50K rows)
    â†“
Preprocessing & Cleaning
    â†“
JSON Format Conversion
    â†“
Class Balancing
    â†“
HuggingFace Upload (Sri1999/creditmix-dataset)
    â†“
Training Pipeline
    â†“
Model Checkpoints
    â†“
GGUF Conversion
    â†“
Inference Deployment
```

---

## 4. Model Architecture

### 4.1 Base Model

**Model:** Qwen/Qwen2.5-3B-Instruct

**Specifications:**
- Parameters: 3 billion
- Architecture: Transformer-based decoder
- Vocabulary: 151,936 tokens
- Context Length: 32,768 tokens
- Quantization: 4-bit (NF4) for training, 8-bit/16-bit for inference

### 4.2 LoRA Configuration

**Rank (r):** 32
**Alpha:** 64
**Dropout:** 0.0
**Target Modules:**
- `q_proj` (Query projection)
- `k_proj` (Key projection)
- `v_proj` (Value projection)
- `o_proj` (Output projection)
- `gate_proj` (Gate projection for MLP)
- `up_proj` (Up projection for MLP)
- `down_proj` (Down projection for MLP)

**Trainable Parameters:**
- LoRA adapters: ~119 MB
- Total model: 3B parameters
- Adapter percentage: ~1.3% of total parameters

### 4.3 Model Variants

| Model | Quantization | Size | Accuracy | Use Case |
|-------|-------------|------|----------|----------|
| **Base** | 8-bit | 3.61 GB | 20% | Baseline comparison |
| **QLoRA** | 4-bit + LoRA | 6.18 GB | 50% | Memory-efficient fine-tuning |
| **LoRA** | 16-bit + LoRA | 6.18 GB | 60% | Best accuracy |

### 4.4 Inference Configuration

**Generation Parameters:**
```python
{
    "max_tokens": 512,
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 40,
    "repeat_penalty": 1.1,
    "stop_sequences": ["</answer>", "\n\n"]
}
```

**Streaming:** Enabled for real-time token generation

---

## 5. User Interface Design

### 5.1 Web UI (Streamlit)

**Layout Structure:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ğŸ¦ Credit Risk Assessment Tool       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‹ Customer Information                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ Age         â”‚ Outstanding â”‚              â”‚
â”‚  â”‚ Occupation  â”‚ Debt        â”‚              â”‚
â”‚  â”‚ Income      â”‚ Credit Util â”‚              â”‚
â”‚  â”‚             â”‚ Payment Beh â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“Š Model Performance                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Base    â”‚  LoRA    â”‚  QLoRA   â”‚         â”‚
â”‚  â”‚  20%     â”‚  60%     â”‚  50%     â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ¤– Select Models to Compare                â”‚
â”‚  â˜‘ QLoRA  â˜ LoRA  â˜ Base                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ” Generate Assessment                     â”‚
â”‚  [Generate Credit Risk Assessment]          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Results:                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ QLoRA Model                         â”‚    â”‚
â”‚  â”‚ <streaming output...>               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Principles:**

1. **Visual Hierarchy**: Clear separation between input, configuration, and results
2. **Color Coding**: Distinct gradient backgrounds for each model
   - QLoRA: Blue gradient (#1e3c72 â†’ #2a5298)
   - LoRA: Orange gradient (#ff6b35 â†’ #f7931e)
   - Base: Purple gradient (#764ba2 â†’ #667eea)
3. **Responsive Layout**: Two-column grid for input fields
4. **Real-time Feedback**: Streaming text display with monospace font
5. **Transparency**: Model performance metrics displayed prominently

### 5.2 Color Palette

| Element | Primary | Secondary | Text |
|---------|---------|-----------|------|
| **QLoRA Container** | #1e3c72 | #2a5298 | #ffffff |
| **LoRA Container** | #ff6b35 | #f7931e | #ffffff |
| **Base Container** | #764ba2 | #667eea | #ffffff |
| **Input Section** | #f5f7fa | #c3cfe2 | #2c3e50 |
| **Buttons** | #ff4b4b | #e03e3e | #ffffff |

### 5.3 Typography

- **Headers**: Bold, 2.5rem (main), 1.5rem (sections)
- **Body Text**: Regular, 1rem
- **Model Titles**: Bold, 1.3rem, white with shadow
- **Streaming Output**: Monospace (Courier New), 0.9rem

---

## 6. API Design

### 6.1 REST API Endpoints

**Base URL:** `http://localhost:8000`

#### 6.1.1 Health Check
```
GET /health
```

**Response:**
```json
{
  "status": "healthy",
  "models_loaded": true
}
```

#### 6.1.2 QLoRA Inference
```
POST /inference/qlora
Content-Type: application/json
```

**Request Body:**
```json
{
  "age": 32,
  "occupation": "Journalist",
  "annual_income": 33470.43,
  "outstanding_debt": 1318.49,
  "credit_utilization": 26.8,
  "payment_behavior": "High_spent_Small_value_payments"
}
```

**Response:**
```json
{
  "model_name": "QLoRA",
  "formatted_input": "Age: 32, Occupation: Journalist, ...",
  "response": "<reasoning>...</reasoning><answer>Good</answer>",
  "processing_time": 2.45
}
```

#### 6.1.3 LoRA Inference
```
POST /inference/lora
Content-Type: application/json
```
(Same request/response structure as QLoRA)

#### 6.1.4 Parallel Inference
```
POST /inference/parallel
Content-Type: application/json
```

**Response:**
```json
{
  "qlora_result": { /* ModelResponse */ },
  "lora_result": { /* ModelResponse */ },
  "total_processing_time": 3.12
}
```

### 6.2 API Features

- **CORS Enabled**: Cross-origin requests allowed
- **Model Preloading**: Models loaded at startup for fast inference
- **Parallel Processing**: ThreadPoolExecutor for concurrent model runs
- **Error Handling**: Structured HTTP exceptions
- **Auto-Documentation**: OpenAPI/Swagger at `/docs`

---

## 7. Training Pipeline Design

### 7.1 Training Strategy

**Method:** GRPO (Group Relative Policy Optimization)

**Rationale:**
- Traditional supervised fine-tuning only teaches the model to mimic outputs
- GRPO uses reinforcement learning to optimize for multiple objectives
- Reward functions guide the model to produce correct format AND correct classification

### 7.2 Multi-Objective Reward Function

```python
def reward_function(prompt, response, ground_truth):
    rewards = []

    # 1. XML Format Validation
    if contains_xml_tags(response):
        rewards.append(1.0)

    # 2. Soft Format Matching
    if has_reasoning_and_answer(response):
        rewards.append(0.5)

    # 3. Strict Format Matching
    if exact_xml_format(response):
        rewards.append(1.0)

    # 4. Category Validation
    if answer_in_valid_categories(response):
        rewards.append(1.0)

    # 5. Correctness Reward
    if extracted_answer == ground_truth:
        rewards.append(2.0)  # Highest weight
    else:
        rewards.append(0.0)

    return sum(rewards)
```

### 7.3 Training Configuration

**Optimizer:** paged_adamw_8bit
**Learning Rate:** 5e-6
**Scheduler:** Cosine annealing
**Batch Size:** 6 per device
**Gradient Accumulation:** 1 step
**Max Steps:** 100
**Warmup Steps:** 5
**Checkpointing:** Every 500 steps (18 checkpoints)

**Hardware:**
- GPU: NVIDIA RTX 4060 (8GB VRAM)
- Memory Optimization: 4-bit quantization + gradient checkpointing

### 7.4 Training Flow

```
Load Base Model (4-bit quantized)
    â†“
Initialize LoRA Adapters
    â†“
Load Balanced Dataset (22,764 examples)
    â†“
GRPO Training Loop (100 steps)
    â”œâ”€â”€ Generate responses
    â”œâ”€â”€ Calculate multi-objective rewards
    â”œâ”€â”€ Update policy
    â””â”€â”€ Save checkpoint every 500 steps
    â†“
Merge Adapters with Base Model
    â†“
Convert to GGUF Format
    â†“
Upload to HuggingFace Hub
```

### 7.5 Evaluation Pipeline

**Test Set:** 10 examples (4 Good, 3 Standard, 3 Bad)

**Metrics:**
- Accuracy: Percentage of correct classifications
- Per-class Precision/Recall
- Format Compliance Rate
- Response Quality (human evaluation)

**Results:**
- Base Model: 2/10 = 20%
- QLoRA Model: 5/10 = 50%
- LoRA Model: 6/10 = 60%

---

## 8. Deployment Architecture

### 8.1 Deployment Options

#### Option 1: Streamlit Web App
```bash
streamlit run src/app.py --server.port 8501
```
- Best for: Interactive demos, internal tools
- Users: Non-technical stakeholders, QA testers

#### Option 2: FastAPI Server
```bash
python src/api_server.py
```
- Best for: Production API, system integrations
- Users: Backend services, mobile apps, web clients

#### Option 3: CLI Inference
```bash
python src/infer.py --checkpoint outputs/checkpoint-8500
```
- Best for: Batch processing, scripting, automation
- Users: Data scientists, DevOps engineers

### 8.2 Containerization (Recommended)

**Dockerfile Structure:**
```dockerfile
FROM python:3.10-slim

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy models and code
COPY models/ /app/models/
COPY src/ /app/src/

# Expose ports
EXPOSE 8000 8501

# Health check
HEALTHCHECK --interval=30s --timeout=10s \
  CMD curl -f http://localhost:8000/health || exit 1

CMD ["uvicorn", "src.api_server:app", "--host", "0.0.0.0"]
```

### 8.3 Scaling Strategy

**Horizontal Scaling:**
- Load balancer (NGINX/Traefik)
- Multiple API server instances
- Shared model storage (NFS/S3)

**Vertical Scaling:**
- Upgrade to GPU instances for faster inference
- Increase memory for larger batch sizes
- Use model quantization (INT8, INT4) for lower latency

### 8.4 Monitoring and Logging

**Metrics to Track:**
- Request latency (p50, p95, p99)
- Throughput (requests/second)
- Model accuracy (online evaluation)
- Error rates
- GPU/CPU utilization
- Memory usage

**Tools:**
- Prometheus + Grafana for metrics
- ELK Stack for log aggregation
- Sentry for error tracking

---

## 9. Security and Privacy

### 9.1 Data Privacy

- **PII Handling**: No personally identifiable information stored
- **Data Retention**: API requests not logged by default
- **Encryption**: HTTPS for all API communications
- **Anonymization**: Input data contains no names, addresses, or SSNs

### 9.2 Model Security

- **Model Signing**: Verify model integrity with checksums
- **Access Control**: API key authentication (to be implemented)
- **Rate Limiting**: Prevent abuse (to be implemented)
- **Input Validation**: Strict schema validation prevents injection attacks

### 9.3 Compliance Considerations

- **GDPR**: Right to explanation (model provides reasoning)
- **Fair Lending**: Monitor for bias in credit decisions
- **Audit Trail**: Log all predictions with timestamps
- **Explainability**: XML reasoning format provides transparency

---

## 10. Performance Considerations

### 10.1 Latency Targets

| Operation | Target | Actual |
|-----------|--------|--------|
| **Model Loading** | < 30s | ~15s |
| **Single Inference** | < 5s | ~2-3s |
| **Parallel Inference** | < 7s | ~3-4s |
| **Streaming First Token** | < 500ms | ~300ms |

### 10.2 Optimization Techniques

1. **Model Quantization**: 4-bit/8-bit reduces memory and increases speed
2. **GGUF Format**: Optimized for CPU inference via llama.cpp
3. **Model Caching**: Load once at startup, reuse for all requests
4. **Parallel Execution**: ThreadPoolExecutor for concurrent model runs
5. **Streaming Output**: Tokens generated incrementally for better UX

### 10.3 Resource Requirements

**Development:**
- CPU: 4 cores minimum
- RAM: 16 GB
- GPU: 8 GB VRAM (for training)
- Storage: 20 GB

**Production (API Server):**
- CPU: 8 cores recommended
- RAM: 32 GB
- GPU: Optional (16 GB for faster inference)
- Storage: 30 GB

### 10.4 Bottlenecks and Mitigations

| Bottleneck | Impact | Mitigation |
|------------|--------|------------|
| **Model Size** | Slow loading | Use quantized GGUF format |
| **Single Thread** | Low throughput | Parallel inference endpoints |
| **Memory** | OOM errors | Gradient checkpointing, 4-bit quantization |
| **I/O** | Disk latency | Load models into RAM, use SSD |

---

## Appendix A: Technology Stack

### Core ML/AI
- **PyTorch**: 2.4.0+cu121
- **Transformers**: 4.55.4
- **Unsloth**: Latest (training optimization)
- **TRL**: Latest (reinforcement learning)
- **PEFT**: Latest (parameter-efficient fine-tuning)
- **bitsandbytes**: 0.41.0+ (quantization)
- **llama.cpp**: Latest (GGUF inference)

### Web Framework
- **Streamlit**: 1.28.0+ (UI)
- **FastAPI**: 0.104.1 (API)
- **Uvicorn**: 0.24.0 (ASGI server)

### Data Processing
- **Pandas**: Latest
- **NumPy**: Latest
- **Datasets**: HuggingFace datasets library

### DevOps
- **Git**: Version control
- **Docker**: Containerization
- **Python**: 3.10+

---

## Appendix B: File Structure

```
fine-tuning-lora-qlora/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                      # Streamlit web UI
â”‚   â”œâ”€â”€ api_server.py               # FastAPI REST API
â”‚   â”œâ”€â”€ infer.py                    # CLI inference script
â”‚   â”œâ”€â”€ load_qlora_model.py         # QLoRA model loader
â”‚   â”œâ”€â”€ load_lora_model.py          # LoRA model loader
â”‚   â”œâ”€â”€ load_base_model.py          # Base model loader
â”‚   â”œâ”€â”€ credit_risk_formatter.py    # Input formatter
â”‚   â”œâ”€â”€ requirements.txt            # Core dependencies
â”‚   â””â”€â”€ api_requirements.txt        # API dependencies
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ checkpoint-500/             # Training checkpoints
â”‚   â”œâ”€â”€ checkpoint-1000/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ train_qlora.ipynb               # GRPO training notebook
â”œâ”€â”€ train_sft_qlora.ipynb           # SFT training notebook
â”œâ”€â”€ trainlora.ipynb                 # Full LoRA training
â”œâ”€â”€ evaluation.ipynb                # Model evaluation
â”œâ”€â”€ preprocessing.ipynb             # Data preprocessing
â”œâ”€â”€ creditmix_dataset.json          # Training dataset
â”œâ”€â”€ evaluation_examples.json        # Test dataset
â”œâ”€â”€ qwen2.5-3b-f16-qlora.gguf       # QLoRA model (6.18 GB)
â”œâ”€â”€ qwen2.5-3b--lora-f16.gguf       # LoRA model (6.18 GB)
â””â”€â”€ qwen2.5-3b-instruct-q8_0.gguf   # Base model (3.61 GB)
```

---

## Document Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0.0 | Nov 2025 | AI/ML Team | Initial design document |

---

**End of Design Document**
